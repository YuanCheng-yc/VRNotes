# Mentimeter

Covers from Week 8 - 10

This is an attempt to collate all mentimeter questions in one MD

## Week 8
Q1\
Which interaction mechanic is commonly deemed to be the most important in immersive AR, VR and MR experiences?
- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All mechanics are equally important

<details>
  <summary>Answer</summary>
  Viewport Control
</details>
<br>

This is for Q2, Q3 & Q4\
![VR Bioreactor Training](MentiImages/w8-01.png)

Q2\
In the VR Bioreactor Training system, what interaction mechanics were implemented?
- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All of the above

<details>
  <summary>Answer</summary>
  Viewport Control
  <br>
  Hand Gestures
</details>
<br>

Q3\
In the VR Bioreactor Training system, is viewport control a passive or active interaction mechanics?
- Passive
- Active

<details>
  <summary>Answer</summary>
  Passive
</details>
<br>

Q4\
In the VR Bioreactor Training system, are hand gestures a passive or active interaction mechanic?
- Passive
- Active

<details>
  <summary>Answer</summary>
  Active
</details>
<br>

This is for Q5, Q6 & Q7\
![360 Video Lecture](MentiImages/w8-02.png)

Q5\
In the 360 Video Lecture, what interaction mechanics were implemented?
- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All of the above

<details>
  <summary>Answer</summary>
  Viewport Control
  <br>
  Hand Gestures
</details>
<br>

Q6\
In the 360 Video Lecture, is viewport control a passive or active interaction mechanics?
- Passive
- Active

<details>
  <summary>Answer</summary>
  Passive
  <br>
  Active
</details>
<br>

Q7\
In the 360 Video Lecture, what form of interaction authenticity is the eye-gaze point-and-click mechanic?
- Natural interaction
- Artifical magical interaction
- Artifical augmented natural interaction

<details>
  <summary>Answer</summary>
  Artifical augmented natural interaction
</details>
<br>

Q8\
Many users tend to route their hands behind the virtual saw blade when asked to place their hands in the target position? What is the primary reason?
- Limited field of view in the VR headset affecting depth perception
- The saw blade simply looks hyper-realistic
- High embodiment via realistic hand representation and precise tracking
- Difficult in accurately perceiving the virtual saw blade's position

<details>
  <summary>Answer</summary>
  High embodiment via realistic hand representation and precise tracking
</details>
<br>

Q9\
![Wk8 Q9](MentiImages/w8-03.png)\
What interaction authenticity is optimal?
- Natural interaction
- Artifical magical interaction
- Artifical augmented natural interaction

<details>
  <summary>Answer</summary>
  Natural interaction
</details>
<br>

Q10\
![Wk8 Q10](MentiImages/w8-04.png)\
What interaction authenticity is optimal?
- Natural interaction
- Artifical magical interaction
- Artifical augmented natural interaction

<details>
  <summary>Answer</summary>
  Natural interaction
</details>
<br>

Q11\
![Wk8 Q11](MentiImages/w8-05.png)\
Which device platform is the most appropriate here?
- Desktop
- Google Cardboard
- Meta Quest 2 (Wireless)
- HTC Vive Pro (Wired)
- Microsoft Hololens

<details>
  <summary>Answer</summary>
  Meta Quest 2 (Wireless)
</details>
<br>

Q12\
![Wk8 Q12](MentiImages/w8-06.png)\
Which device platform is the most appropriate here?
- Desktop
- Google Cardboard
- Meta Quest 2 (Wireless)
- HTC Vive Pro (Wired)
- Microsoft Hololens

<details>
  <summary>Answer</summary>
  HTC Vive Pro (Wired)
</details>
<br>

Q13\
![Wk8 Q13](MentiImages/w8-07.png)\
What form of GUI implementation is best suited for this use case?
- GUI on a virtual paper (using a virtual pen)
- GUI on a 3D plane anchored in virtual world locations
- Real-world quiz on real paper (take off HMD when interacting)

<details>
  <summary>Answer</summary>
  GUI on a 3D plane anchored in virtual world locations
  <br>
  Real-world quiz on real paper (take off HMD when interacting)
</details>
<br>

Q14\
![Wk8 Q14](MentiImages/w8-08.png)\
What form of GUI implementation is best suited for this use case?
- GUI on a virtual paper (using a virtual pen)
- GUI on a 3D plane anchored in virtual world locations
- Real-world quiz on real paper (take off HMD when interacting)

<details>
  <summary>Answer</summary>
  GUI on a 3D plane anchored in virtual world locations
</details>
<br>

Q15\
![Wk8 Q15](MentiImages/w8-09.png)\
- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

<details>
  <summary>Answer</summary>
  Teleportation
</details>
<br>

Q16\
![Wk8 Q16](MentiImages/w8-10.png)\
- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

<details>
  <summary>Answer</summary>
  Tracking real movement in physical space
</details>
<br>

Q17\
![Wk8 Q17](MentiImages/w8-11.png)\
- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

<details>
  <summary>Answer</summary>
  Walking-in-place (WIP) with HTC Vive HMD and trackers
</details>
<br>

## Week 9
Q1\
Implement a jump action in your Babylon.js scene when the user presses the keyboard spacebar. Which trigger should you use in the ActionManager?
- OnPickTrigger
- OnInteractionEnterTrigger
- OnKeyUpTrigger
- NothingTrigger

<details>
  <summary>Answer</summary>
  OnKeyUpTrigger
</details>
<br>

Q2\
![alt text](MentiImages/w9-1.png)\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  ActionManager
</details>
<br>

Q3\
In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its approximity to different objects.\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  Observables
</details>
<br>

Q4\
![alt text](MentiImages/w9-2.png)\
In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its approximity to different objects.\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  Observables
</details>
<br>

Q5\
![alt text](MentiImages/w9-3.png)\
In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its approximity to different objects.\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  ActionManager
</details>
<br>

Q6\
![alt text](MentiImages/w9-4.png)\
In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its approximity to different objects.\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  Behaviors
</details>
<br>

Q7\
![alt text](MentiImages/w9-5.png)\
In total, how many observers were used here?
- 0
- 1
- 2
- 3
- 4
- 5

<details>
  <summary>Answer</summary>
  2
</details>
<br>

Q8\
![alt text](MentiImages/w9-6.png)\
In total, how many observers were used here?
- 0
- 1
- 2
- 3
- 4
- 5

<details>
  <summary>Answer</summary>
  2
</details>
<br>

Q9\
![alt text](MentiImages/w9-7.png)\
In total, how many observers were used here?
- 0
- 1
- 2
- 3
- 4
- 5

<details>
  <summary>Answer</summary>
  1
</details>
<br>

Q10\
![alt text](MentiImages/w9-8.png)\
What is the mechanics of the following code?
- It adds an Observable to pointerDragBehavior of the sphere
- It adds an Observer to the sphere
- It adds an Observer to onDragObservable of the pointerDragBehavior
- It adds and Observable to the sphere

<details>
  <summary>Answer</summary>
  It adds an Observer to onDragObservable of the pointerDragBehavior
</details>
<br>

Q11\
Which API class in Babylon.js will allow you to easily add UI controls to easily manipulate the position, rotation, and scale of meshes in your scene?\
- MultiPointerScaleBehavior
- GizmoManager
- PointerDragBehavior
- WebXRFeaturesManager

<details>
  <summary>Answer</summary>
  GizmoManager
</details>
<br>

Q12\
![alt text](MentiImages/w9-9.png)\
What does ToTeleport do in the following Babylon.js code?\
- Sets the duration of the teleportation animation
- Sets the maximum time to complete the teleportation
- Sets the minimum delay between each teleportation trigger
- Sets the time in to hold the button before teleportation triggers

<details>
  <summary>Answer</summary>
  Sets the time in to hold the button before teleportation triggers
</details>
<br>

## Week 10
Q1\
Which of the following describes immersion from a systems perspective?
- Wide FOV
- Higher spatial presence
- Teleportation feature
- High-fidelity graphics
- Lower cybersickness
- 6-DOF inside-out tracking

<details>
  <summary>Answer</summary>
  Wide FOV
  <br>
  Teleportation feature
  <br>
  High-fidelity graphics
  <br>
  6-DOF inside-out tracking
</details>
<br>

Q2\
**IMAGE REQUIRED**\
Which popular experiential construct(s) of immersion is/are relevant here?
- Flow
- Presence
- Cybersickness

<details>
  <summary>Answer</summary>
  Flow
  <br>
  Cybersickness
</details>
<br>

Q3\
Which of the following implementations will this design translate into?
- Constrict the FOV when moving
- Test users using the VRSQ
- Test users using the IPQ
- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment

<details>
  <summary>Answer</summary>
  Constrict the FOV when moving
  <br>
  Create a teleportation locomotion feature
</details>
<br>

Q4\
What data collection methods can be appropriate here?
- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechnisms to observe users

<details>
  <summary>Answer</summary>
  Let users fill in the VRSQ
  <br>
  Perform semi-structured interviews with users
  <br>
  Create telemetry tracking mechnisms to observe users
</details>
<br>

Q5\
**IMAGE REQUIRED**\
Which of the following implementations will this design translate into?
- Constrict the FOV when moving
- Test users using the VRSQ
- Create a zero-gravity arena that simulates physical weightlessness
- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment
- Create gamification features to guide users through the experience

<details>
  <summary>Answer</summary>
  Create a zero-gravity arena that simulates physical weightlessness
  <br>
  Create a high-fidelity realistic 3D environment
</details>
<br>

Q6\
**IMAGE REQUIRED**\
What data collection methods can be appropriate here?
- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechnisms to observe users

<details>
  <summary>Answer</summary>
  Let users fill in the IPQ
  <br>
  Perform semi-structured interviews with users
  <br>
  Create telemetry tracking mechnisms to observe users
</details>
<br>

Q7\
**IMAGE REQUIRED**\
Which of the following implementations will this design translate into?
- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment
- Create a finger-tracked hand gestures to inspect museum artifacts
- Create gamification features to guide users through the experience

<details>
  <summary>Answer</summary>
  Create gamification features to guide users through the experience
</details>
<br>

Q8\
**IMAGE REQUIRED**\
What data collection methods can be appropriate here?
- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechnisms to observe users

<details>
  <summary>Answer</summary>
  Let users fill in the FSS
  <br>
  Perform semi-structured interviews with users
  <br>
  Create telemetry tracking mechnisms to observe users
</details>
<br>