# Interaction
[Discussion Link](https://github.com/orgs/sit-dia/discussions/14)

## Viewpoint Control
- Basically controlling the camera
- Is a passive interaction
- Intertial Measurement Units (IMUs) use accelerometers and gyroscopes to determine where a device is in 3D space

## Hand Gestures
- Haptic Gloves
- Computer Vision-based Finger Tracking
- Dedicated VR controllers

## Body Gestures
- Embodiment: "the feeling of being in control of a virtual representation of the human self"
- Hand gestures are partial embodiment, because only the hands are being controlled
- IMU Trackers
- 360 degree treadmills
- Haptic suits
- No real desktop replacement using desktop modalities (e.g. keyboard, mouse) to give embodiment

## Interaction Authenticity
- Interaction Authenticity: "the consideration of whether the desired experience should be natural or artificial"

### Natural Interactions
- Natural Interactions: "interactions where the outcome is very close to what is done in the real world"

### Artificial Interactions
- Artificial Interactions: "interactions that are imossible in the real world"

#### Magical Interactions
- Plausibility Illusion: "events that happen in the virtual world closely affects the perception of how credible these things can actually happen IRL"
- Having the Plausibility Illusion is the key to providing an immersive experience for the user
- E.g literally controlling the flow of time by moving (Superhot)

#### Augmented Natural Interactions
- Allows users to perform higly exaggerated versions of a familiar IRL action
- E.g. super high jumps in video games

## Interaction Use Cases

### GUI Interactions
- GUI = Graphical User Interface
- HUD = Heads Up Display
- HMD = Head Mounted Device

#### E.g. Meta Quest 2
-  An "all-in=one" VR HMD, where all selections and menu interactions are displayed in the VR display itself
- It uses Viewpoint Control & Hand Gestures 
- Creates a laser pointer ray, acting as an extension of the VR controllers, to click options in the menu with a trigger button

#### E.g. Google Cardboard
- Makes finger point at things by using Viewpoint Control, known as Gaze Control (because there are no controllers)
- Clicks in menus are done by staring at menu options long enough [Editor's Note: THAT'S HILARIOUS.]

### Locomotion Interactions
- Locomotion Interactions: "the ability to perform spatial navigation in the virtual environment"
- Can be pretty tricky to get right, especially with IRL spatial constaints (the room you're in can only be so big before bumping into stuff)
- Can be done by combining Viewpoint Control, Hand Gestures and Body Gestures
- Alternatively, users can move around with just teleporting from place to place instead, but that hampers Immersion a lot

# End  

Link: [Developing Immersive Applications: Interaction (youtube.com)](https://www.youtube.com/watch?v=dKRWH7O81yk)
> Written with [StackEdit](https://stackedit.io/).
